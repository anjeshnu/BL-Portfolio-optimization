{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Black-Litterman Portfolio Optimization - Quick Start\n",
    "\n",
    "This notebook demonstrates a basic workflow for using the Black-Litterman model for portfolio optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src import data_loader\n",
    "from src import factors\n",
    "from src import covariance\n",
    "from src import black_litterman\n",
    "from src import optimization\n",
    "from src import visualization\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load Data\n",
    "\n",
    "Load all required data including ETF prices, factor data, and CMA priors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load all data\n",
    "data = data_loader.load_all_data(data_dir='../data')\n",
    "\n",
    "print(\"Available data:\")\n",
    "for key in data.keys():\n",
    "    if isinstance(data[key], pd.DataFrame) or isinstance(data[key], pd.Series):\n",
    "        print(f\"  {key}: Shape {data[key].shape}\")\n",
    "\n",
    "# Extract key components\n",
    "returns = data['returns_monthly']\n",
    "excess_returns = data['excess_returns']\n",
    "cma_priors = data['cma_priors']\n",
    "\n",
    "print(\"\\nAssets in universe:\")\n",
    "print(returns.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Build Factor Model\n",
    "\n",
    "Construct custom factors and estimate factor exposures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Build custom factors\n",
    "custom_factors = factors.build_custom_factors(returns)\n",
    "\n",
    "# Combine with Fama-French factors\n",
    "ff_factors = data['ff_factors']['FF5']\n",
    "all_factors = factors.combine_factors(ff_factors, custom_factors)\n",
    "\n",
    "# Estimate factor model\n",
    "factor_results = factors.factor_model_analysis(\n",
    "    excess_returns,\n",
    "    ff_factors,\n",
    "    custom_factors\n",
    ")\n",
    "\n",
    "print(\"Factor Model R-squared:\")\n",
    "print(factor_results['r_squared'].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Estimate Covariance Matrix\n",
    "\n",
    "Use Ledoit-Wolf shrinkage for robust covariance estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Estimate covariance using Ledoit-Wolf shrinkage\n",
    "cov_matrix, shrinkage = covariance.ledoit_wolf_shrinkage(excess_returns)\n",
    "\n",
    "print(f\"Shrinkage intensity: {shrinkage:.3f}\")\n",
    "\n",
    "# Visualize correlation matrix\n",
    "fig = visualization.plot_correlation_matrix(\n",
    "    excess_returns,\n",
    "    title=\"Asset Correlation Matrix\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Black-Litterman Model\n",
    "\n",
    "Compute posterior expected returns incorporating views."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize Black-Litterman model with CMA priors\n",
    "bl_model = black_litterman.BlackLittermanModel(\n",
    "    prior_returns=cma_priors,\n",
    "    cov_matrix=cov_matrix,\n",
    "    tau=0.025\n",
    ")\n",
    "\n",
    "# Add views (example)\n",
    "views = {\n",
    "    \"SPY\": 0.10,  # US equities will return 10%\n",
    "    \"VWO\": 0.12,  # EM will return 12%\n",
    "}\n",
    "\n",
    "bl_model.add_absolute_views(views, confidences={\"SPY\": 0.7, \"VWO\": 0.6})\n",
    "\n",
    "# Compute posterior\n",
    "posterior_returns, posterior_cov = bl_model.compute_posterior()\n",
    "\n",
    "# Compare prior and posterior\n",
    "comparison = bl_model.get_view_deviations()\n",
    "print(\"\\nPrior vs Posterior Expected Returns:\")\n",
    "print(comparison[['Prior', 'Posterior', 'Deviation']].round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Portfolio Optimization\n",
    "\n",
    "Optimize portfolio weights using posterior expected returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Mean-variance optimization\n",
    "weights_mv = optimization.mean_variance_optimization(\n",
    "    expected_returns=posterior_returns,\n",
    "    cov_matrix=cov_matrix,\n",
    "    risk_aversion=2.0,\n",
    "    constraints={\"long_only\": True, \"max_weight\": 0.4}\n",
    ")\n",
    "\n",
    "# Maximum Sharpe ratio\n",
    "weights_sharpe = optimization.max_sharpe_ratio(\n",
    "    expected_returns=posterior_returns,\n",
    "    cov_matrix=cov_matrix,\n",
    "    constraints={\"long_only\": True}\n",
    ")\n",
    "\n",
    "# Risk parity\n",
    "weights_rp = optimization.risk_parity_portfolio(cov_matrix)\n",
    "\n",
    "# Compare portfolios\n",
    "all_weights = pd.DataFrame({\n",
    "    \"Mean-Variance\": weights_mv,\n",
    "    \"Max Sharpe\": weights_sharpe,\n",
    "    \"Risk Parity\": weights_rp\n",
    "})\n",
    "\n",
    "print(\"\\nOptimal Portfolio Weights:\")\n",
    "print(all_weights.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot portfolio weights\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "for i, col in enumerate(all_weights.columns):\n",
    "    all_weights[col].sort_values().plot(\n",
    "        kind='barh',\n",
    "        ax=axes[i],\n",
    "        color='steelblue',\n",
    "        title=col\n",
    "    )\n",
    "    axes[i].set_xlabel('Weight')\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Portfolio statistics\n",
    "print(\"\\nPortfolio Statistics (Annualized):\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for name, weights in zip(all_weights.columns, [weights_mv, weights_sharpe, weights_rp]):\n",
    "    stats = optimization.portfolio_statistics(\n",
    "        weights,\n",
    "        posterior_returns,\n",
    "        cov_matrix\n",
    "    )\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Expected Return: {stats['annual_return']:.2%}\")\n",
    "    print(f\"  Volatility:      {stats['annual_volatility']:.2%}\")\n",
    "    print(f\"  Sharpe Ratio:    {stats['annual_sharpe']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Efficient Frontier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Compute efficient frontier\n",
    "frontier_returns, frontier_vols, _ = optimization.efficient_frontier(\n",
    "    posterior_returns,\n",
    "    cov_matrix,\n",
    "    n_points=50\n",
    ")\n",
    "\n",
    "# Plot efficient frontier with portfolios\n",
    "portfolio_stats = []\n",
    "for weights in [weights_mv, weights_sharpe, weights_rp]:\n",
    "    stats = optimization.portfolio_statistics(weights, posterior_returns, cov_matrix)\n",
    "    portfolio_stats.append(stats)\n",
    "\n",
    "portfolio_returns = pd.Series([s['return'] for s in portfolio_stats])\n",
    "portfolio_vols = pd.Series([s['volatility'] for s in portfolio_stats])\n",
    "\n",
    "fig = visualization.plot_efficient_frontier(\n",
    "    frontier_returns,\n",
    "    frontier_vols,\n",
    "    portfolio_returns,\n",
    "    portfolio_vols,\n",
    "    all_weights.columns.tolist()\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated:\n",
    "1. Loading and preparing data\n",
    "2. Building factor models\n",
    "3. Estimating robust covariance matrices\n",
    "4. Incorporating views with Black-Litterman\n",
    "5. Optimizing portfolio weights\n",
    "6. Analyzing and visualizing results\n",
    "\n",
    "For more advanced analysis, see the `main_analysis.ipynb` notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
